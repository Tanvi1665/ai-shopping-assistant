# ğŸ›ï¸ AI Shopping Assistant for the Visually Impaired

An AI-powered voice and vision assistant that helps visually impaired individuals identify everyday items through object detection and speech interaction. Built using Python, YOLOv5, and speech recognition technologies.

---

## ğŸš€ Features

- ğŸ¤ Voice-controlled assistant  
- ğŸ“· Real-time object detection using webcam  
- ğŸ§  YOLOv5 deep learning model  
- ğŸ”Š Text-to-speech output for item details  
- ğŸ›’ Product-specific info: name, price, and description  
- âœ… Fully offline-capable  

---

## ğŸ“¸ How It Works

1. User speaks: **"What is in front of me"**  
2. The assistant:
   - Captures an image using webcam  
   - Detects the most prominent object using YOLOv5  
   - Matches it with product information  
   - Speaks the item's name, price, and description  

---

## ğŸ§  Tech Stack

- Python  
- YOLOv5 (via `torch.hub`)  
- OpenCV â€“ camera capture  
- SpeechRecognition â€“ voice input  
- Pyttsx3 â€“ text-to-speech  
- Pandas, Seaborn â€“ used by YOLO internally  

---

## ğŸ“‚ Project Structure

ai_shopping_assistant/
â”œâ”€â”€ main_app.py # Main script to run the assistant
â”œâ”€â”€ camera.py # Captures webcam image
â”œâ”€â”€ tts.py # Converts text to speech
â”œâ”€â”€ voice_input.py # Handles microphone input
â”œâ”€â”€ object_detection.py # YOLOv5 object detection logic
â”œâ”€â”€ product_info.py # Product details dictionary
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md # Project description
